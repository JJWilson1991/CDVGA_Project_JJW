# Overview

Title of project: Temporal and Spatial Patterns in Distemper Virus Cases Reported to SCWDS 1975-2013

Author of project: Jonathan Wilson


# Specific project content evaluation


## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments

Background and introduction is well-cited and context of the project is given. The US data is sparse in this field and this project will look at survelliance data to understand these patterns. Maybe just add a little more about cases previously looked at in the South East to provide comparison since that is what your data focused on.

### Summary assessment

* strong contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

The questions are clear, but maybe put why you are asking these certain questions, especially in regards to land use.

### Summary assessment

* question/hypotheses somewhat explained



## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

### Feedback and Comments

Data and source is explained. There is no codebook provided but the columns in the raw data files are self-explanatory.

### Summary assessment

* source and overall structure of data well explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

Data is cleaned and processed and all steps are well explained on the CDVP_Processing script. You mention that case number column will be taken out but it hasn't. The Second_Data_Process is not commented on and is "hidden", but it looks like you were just adding months into the data table. The exploratory analysis script is pretty thorough and it would be good to put more summary of what you explored in the manuscript itself. The supplemental material had a lot of interesting graphs that should be at least referenced in the main manuscript.

### Summary assessment

* essentially no weaknesses in wrangling and exploratory component



## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

### Feedback and Comments

You did several different spacial analysis and mapping scripts which were interesting to look at. The predictor models were a clever way to look at your two species together. I think if you just explained more in your manuscript what your analyses meant, it would make it more comprehesive. For instance, what does Ripley's K analysis mean for your data? 

### Summary assessment

* strong and reasonable analysis, but needs a little more work

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

Your mapping coding skills are great! I definitely learned a bit working through your code. I liked the maps over time. I didn't really understand the Ripley's K analysis unless I went to google, so it might help to add more explanation into that figure.

### Summary assessment

* results are very well presented


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

Study findings are interpreted and properly discussed along with literature references. Strengths and limitations are acknowledged, especially in terms of the surveillance of this data set. I think you drew reasonable conclusions here. 

### Summary assessment

* strong, complete and clear discussion


# Overall project content evaluation


## Structure
Is the project well structured? Are files in well labeled folders? Do files have reasonable names? Are all "junk" files not needed for analysis/reproduction removed? By just looking at files and folders, can you get an idea of how things fit together?

### Feedback and Comments

Several of the ReadMe files are still what was on the template. There are template files of the orignial template copy. Other than that, everything is well structured. Should Presence_time.html and Species_time.html in the analysis_code be placed in the results folder?

### Summary assessment

* mostly clear, but some confusing parts (e.g. useless files, things in the wrong folders)


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

Documentation was consistent throughout, except for Spatial Analysis could use more context, and Time Series didn't really have anything in the beginning.

### Summary assessment

* decently documented with some gaps




## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention?

### Feedback and Comments

I had a few issues, mainly the Here code needed to be set to "here::here" in order to work. 


### Summary assessment

* small parts not reproducible or required manual intervention 



## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

### Feedback and Comments

Different ways of displaying the data were done, however I think one more model to compare against your predictor model would have been nice.

### Summary assessment

* decent level of thoroughness



## Further comments

I really liked your project's topic. Your mapping code must have taken a lot of work and I'm really impressed how you displayed your results. I think just documenting your code a bit more would help just to understand what/why you are doing something. Your manuscript is really good for the introduction and discussion. I think just explaining/summarizing the actual exploratory results and maybe including a few more graphs would make your paper stronger. Even if you just refer to graphs in the Supplemental file. 

Great job, Jonathan!




